<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Background Guard</title>
  <style>
    body, html { margin:0; padding:0; background:#000; height: 100vh; overflow: hidden; }
    #container {
      position: relative;
      width: 100vw;
      height: 100vh;
      display: flex;
      justify-content: center;
      align-items: center;
    }
    #webcam, #overlay {
      position: absolute;
      transform: scaleX(-1); 
      max-width: 100%;
      max-height: 100%;
    }
    #status {
      position: absolute;
      top: 20px;
      left: 50%;
      transform: translateX(-50%);
      color: white;
      font-family: sans-serif;
      background: rgba(0, 0, 0, 0.7);
      padding: 10px 20px;
      border-radius: 20px;
      z-index: 10;
      pointer-events: none;
      text-align: center;
    }
  </style>
</head>
<body>
  <div id="status">Loading System...<br><small>(Keep this window open)</small></div>
  <div id="container">
    <video id="webcam" autoplay muted playsinline></video>
    <canvas id="overlay"></canvas>
  </div>

  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js" crossorigin="anonymous"></script>

  <script type="module">
    import { HandLandmarker, FaceLandmarker, FilesetResolver }
      from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0";

    let handLandmarker, faceLandmarker;
    let audioCtx;
    let lastBeep = 0;
    let faceZone = null;
    let videoElement = null;
    let canvasElement = null;
    let ctx = null;

    // --- SETTINGS YOU REQUESTED ---
    const BEEP_COOLDOWN = 800;   // Faster: 0.8 seconds between sounds
    const BOX_WIDTH_SCALE = 0.6; // Narrower: Only uses 60% of face width
    
    // --- WEB WORKER HACK (To run in background tabs) ---
    // This creates a "timer" that runs in a separate thread, forcing the browser
    // to pay attention even if the tab is hidden.
    const workerBlob = new Blob([`
      self.onmessage = function(e) {
        if (e.data === "start") {
          setInterval(() => { postMessage("tick"); }, 100); // Check every 100ms
        }
      };
    `], { type: "text/javascript" });
    const worker = new Worker(URL.createObjectURL(workerBlob));

    async function init() {
      const status = document.getElementById("status");
      videoElement = document.getElementById("webcam");
      canvasElement = document.getElementById("overlay");
      ctx = canvasElement.getContext("2d");

      // 1. Audio
      try { audioCtx = new (window.AudioContext || window.webkitAudioContext)(); } 
      catch (e) {}

      // 2. Load Models
      const vision = await FilesetResolver.forVisionTasks(
        "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm"
      );
      
      handLandmarker = await HandLandmarker.createFromOptions(vision, {
        baseOptions: {
          modelAssetPath: "https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task",
          delegate: "GPU"
        },
        runningMode: "VIDEO",
        numHands: 1
      });

      faceLandmarker = await FaceLandmarker.createFromOptions(vision, {
        baseOptions: {
          modelAssetPath: "https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task",
          delegate: "GPU"
        },
        runningMode: "VIDEO",
        numFaces: 1
      });

      status.innerText = "Active. You can switch tabs now.";

      // 3. Start Camera
      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      videoElement.srcObject = stream;
      
      videoElement.addEventListener("loadeddata", () => {
        canvasElement.width = videoElement.videoWidth;
        canvasElement.height = videoElement.videoHeight;
        
        // Start the Background Worker
        worker.postMessage("start");
      });
    }

    // This function runs every time the Worker sends a "tick" (10x per second)
    // regardless of whether the tab is focused or not.
    worker.onmessage = function(e) {
      if (e.data === "tick") {
        runDetection();
      }
    };

    function runDetection() {
      if (!handLandmarker || !faceLandmarker || !videoElement || videoElement.readyState < 2) return;

      const now = performance.now();
      
      // 1. Clear Screen
      ctx.clearRect(0, 0, ctx.canvas.width, ctx.canvas.height);

      // 2. Detect Face
      const faceResult = faceLandmarker.detectForVideo(videoElement, now);
      if (faceResult.faceLandmarks && faceResult.faceLandmarks.length > 0) {
        updateFaceZone(faceResult.faceLandmarks[0]);
        drawFaceZone(ctx);
      } else {
        faceZone = null;
      }

      // 3. Detect Hands
      if (faceZone) {
        const handResult = handLandmarker.detectForVideo(videoElement, now);
        if (handResult.landmarks && handResult.landmarks.length > 0) {
          const hand = handResult.landmarks[0];
          
          // Draw Hand (Light Green)
          drawConnectors(ctx, hand, HAND_CONNECTIONS, { color: "rgba(0, 255, 0, 0.2)", lineWidth: 2 });

          if (checkCollision(hand)) {
             // Red Alert
             drawConnectors(ctx, hand, HAND_CONNECTIONS, { color: "rgba(255, 0, 0, 0.9)", lineWidth: 4 });
             if (now - lastBeep > BEEP_COOLDOWN) {
               playNotificationSound();
               lastBeep = now;
             }
          }
        }
      }
    }

    // --- NARROW BOX LOGIC ---
    function updateFaceZone(landmarks) {
      // Points: 1(Nose), 152(Chin), 234(Left Face Edge), 454(Right Face Edge)
      const nose = landmarks[1];
      const chin = landmarks[152];
      const leftEdge = landmarks[234].x;
      const rightEdge = landmarks[454].x;

      // Calculate Center and Width
      const centerX = (leftEdge + rightEdge) / 2;
      const fullWidth = Math.abs(rightEdge - leftEdge);
      
      // Make width narrower based on your request
      const scaledWidth = fullWidth * BOX_WIDTH_SCALE; 

      faceZone = {
        minX: centerX - (scaledWidth / 2),
        maxX: centerX + (scaledWidth / 2),
        minY: nose.y - 0.04, // Slightly above nose
        maxY: chin.y + 0.05  // Slightly below chin
      };
    }

    function drawFaceZone(ctx) {
      if (!faceZone) return;
      const w = ctx.canvas.width;
      const h = ctx.canvas.height;
      
      const bx = faceZone.minX * w;
      const by = faceZone.minY * h;
      const bw = (faceZone.maxX - faceZone.minX) * w;
      const bh = (faceZone.maxY - faceZone.minY) * h;

      ctx.strokeStyle = "rgba(0, 200, 255, 0.4)";
      ctx.lineWidth = 2;
      ctx.strokeRect(bx, by, bw, bh);
    }

    function checkCollision(hand) {
      if (!faceZone) return false;
      const tips = [8, 4, 12]; // Index, Thumb, Middle
      for (let i of tips) {
        const x = hand[i].x;
        const y = hand[i].y;
        if (x > faceZone.minX && x < faceZone.maxX && y > faceZone.minY && y < faceZone.maxY) {
          return true;
        }
      }
      return false;
    }

    function playNotificationSound() {
      if (!audioCtx) return;
      if (audioCtx.state === 'suspended') audioCtx.resume();

      const t = audioCtx.currentTime;
      const osc = audioCtx.createOscillator();
      const gain = audioCtx.createGain();

      osc.type = "triangle"; 
      // Quick Ding
      osc.frequency.setValueAtTime(700, t);
      osc.frequency.setValueAtTime(0, t + 0.1); 

      gain.gain.setValueAtTime(0.1, t);
      gain.gain.linearRampToValueAtTime(0.1, t + 0.05);
      gain.gain.setValueAtTime(0, t + 0.1);

      osc.connect(gain).connect(audioCtx.destination);
      osc.start();
      osc.stop(t + 0.2);
    }

    init();
  </script>
</body>
</html>
