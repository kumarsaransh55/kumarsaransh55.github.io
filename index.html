<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Dynamic Face Guard</title>
  <style>
    body, html { margin:0; padding:0; background:#000; height: 100vh; overflow: hidden; }
    #container {
      position: relative;
      width: 100vw;
      height: 100vh;
      display: flex;
      justify-content: center;
      align-items: center;
    }
    /* Mirror the video */
    #webcam, #overlay {
      position: absolute;
      transform: scaleX(-1); 
      max-width: 100%;
      max-height: 100%;
    }
    #status {
      position: absolute;
      top: 20px;
      left: 50%;
      transform: translateX(-50%);
      color: white;
      font-family: sans-serif;
      background: rgba(0, 0, 0, 0.6);
      padding: 10px 20px;
      border-radius: 20px;
      z-index: 10;
      pointer-events: none;
      text-align: center;
    }
  </style>
</head>
<body>
  <div id="status">Loading Face & Hand AI...<br><small>(Please wait 5-10 seconds)</small></div>
  <div id="container">
    <video id="webcam" autoplay muted playsinline></video>
    <canvas id="overlay"></canvas>
  </div>

  <!-- MediaPipe Libraries -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js" crossorigin="anonymous"></script>

  <script type="module">
    import { HandLandmarker, FaceLandmarker, FilesetResolver }
      from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0";

    let handLandmarker, faceLandmarker;
    let audioCtx;
    let lastBeep = 0;
    
    // CONFIGURATION
    const BEEP_COOLDOWN = 1500; // 1.5 seconds silence between alerts
    
    // VARIABLES TO STORE FACE COORDINATES
    let faceZone = null; // Will store {minX, maxX, minY, maxY}

    async function init() {
      const video = document.getElementById("webcam");
      const overlay = document.getElementById("overlay");
      const ctx = overlay.getContext("2d");
      const status = document.getElementById("status");

      // 1. Audio Setup
      try {
        audioCtx = new (window.AudioContext || window.webkitAudioContext)();
      } catch (e) { console.error("Audio API error"); }

      // 2. Load Vision Models (Face AND Hand)
      const vision = await FilesetResolver.forVisionTasks(
        "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm"
      );
      
      // Load Hand Tracker
      handLandmarker = await HandLandmarker.createFromOptions(vision, {
        baseOptions: {
          modelAssetPath: "https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task",
          delegate: "GPU"
        },
        runningMode: "VIDEO",
        numHands: 1
      });

      // Load Face Tracker
      faceLandmarker = await FaceLandmarker.createFromOptions(vision, {
        baseOptions: {
          modelAssetPath: "https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task",
          delegate: "GPU"
        },
        runningMode: "VIDEO",
        numFaces: 1
      });

      status.innerText = "System Active. Tracking Face.";

      // 3. Start Camera
      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      video.srcObject = stream;
      video.addEventListener("loadeddata", () => {
        overlay.width = video.videoWidth;
        overlay.height = video.videoHeight;
        startDetectionLoop(video, ctx);
      });
    }

    function startDetectionLoop(video, ctx) {
      const loop = () => {
        const now = performance.now();
        
        // A. Draw video frame
        ctx.clearRect(0, 0, ctx.canvas.width, ctx.canvas.height);
        
        // B. Detect Face first (To set the Zone)
        if (faceLandmarker) {
          const faceResult = faceLandmarker.detectForVideo(video, now);
          if (faceResult.faceLandmarks && faceResult.faceLandmarks.length > 0) {
            updateFaceZone(faceResult.faceLandmarks[0]);
            drawFaceZone(ctx); // Visualize the zone
          } else {
            faceZone = null; // No face detected
          }
        }

        // C. Detect Hands
        if (handLandmarker && faceZone) {
          const handResult = handLandmarker.detectForVideo(video, now);
          
          if (handResult.landmarks && handResult.landmarks.length > 0) {
            const hand = handResult.landmarks[0];
            
            // Draw Hand (Visual Feedback)
            drawConnectors(ctx, hand, HAND_CONNECTIONS, { color: "rgba(0, 255, 0, 0.3)", lineWidth: 2 });

            // Check Collision
            if (checkCollision(hand)) {
              // CHANGE COLOR TO RED
              drawConnectors(ctx, hand, HAND_CONNECTIONS, { color: "rgba(255, 0, 0, 1)", lineWidth: 4 });
              
              if (now - lastBeep > BEEP_COOLDOWN) {
                playNotificationSound();
                lastBeep = now;
              }
            }
          }
        }

        requestAnimationFrame(loop);
      };
      loop();
    }

    // --- LOGIC: CALCULATE THE MOUSTACHE ZONE ---
    function updateFaceZone(landmarks) {
      // Key Points: 1(Nose Tip), 152(Chin), 234(Left Cheek), 454(Right Cheek)
      // We want the box to cover Nose down to Chin.
      const nose = landmarks[1]; 
      const chin = landmarks[152];
      const leftCheek = landmarks[234];
      const rightCheek = landmarks[454];

      // Add a little padding/margin so it's not too tight
      const padding = 0.05; 

      faceZone = {
        minX: Math.min(leftCheek.x, rightCheek.x) - padding,
        maxX: Math.max(leftCheek.x, rightCheek.x) + padding,
        minY: nose.y - 0.05, // Start slightly above nose
        maxY: chin.y + 0.05  // End slightly below chin
      };
    }

    function drawFaceZone(ctx) {
      if (!faceZone) return;
      const w = ctx.canvas.width;
      const h = ctx.canvas.height;

      const bx = faceZone.minX * w;
      const by = faceZone.minY * h;
      const bw = (faceZone.maxX - faceZone.minX) * w;
      const bh = (faceZone.maxY - faceZone.minY) * h;

      ctx.strokeStyle = "rgba(0, 200, 255, 0.6)"; // Blue Box
      ctx.lineWidth = 3;
      ctx.strokeRect(bx, by, bw, bh);
    }

    function checkCollision(hand) {
      if (!faceZone) return false;
      // Check Index Tip (8) and Thumb Tip (4) and Middle Tip (12)
      const tips = [8, 4, 12];
      
      for (let i of tips) {
        const x = hand[i].x;
        const y = hand[i].y;
        if (x > faceZone.minX && x < faceZone.maxX && y > faceZone.minY && y < faceZone.maxY) {
          return true;
        }
      }
      return false;
    }

    // --- NEW SOUND: SHARP NOTIFICATION ---
    function playNotificationSound() {
      if (!audioCtx) return;
      if (audioCtx.state === 'suspended') audioCtx.resume();

      const t = audioCtx.currentTime;
      const osc = audioCtx.createOscillator();
      const gain = audioCtx.createGain();

      // "Triangle" wave is sharper than Sine, but not annoying like Square
      osc.type = "triangle"; 

      // PING - PING Pattern (Double Beep)
      osc.frequency.setValueAtTime(880, t);       // High Pitch (A5)
      osc.frequency.setValueAtTime(880, t + 0.1); 
      osc.frequency.setValueAtTime(0, t + 0.11);  // Silence
      osc.frequency.setValueAtTime(587, t + 0.15); // Lower Pitch (D5)

      // Volume Envelope (Short and crisp)
      gain.gain.setValueAtTime(0.1, t);
      gain.gain.linearRampToValueAtTime(0.1, t + 0.1);
      gain.gain.setValueAtTime(0.0, t + 0.11); // Cut
      gain.gain.setValueAtTime(0.1, t + 0.15); // Second beep
      gain.gain.exponentialRampToValueAtTime(0.001, t + 0.4); // Fade out

      osc.connect(gain).connect(audioCtx.destination);
      osc.start();
      osc.stop(t + 0.5);
    }

    init();
  </script>
</body>
</html>
